{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-05T18:50:48.038070Z",
     "iopub.status.busy": "2020-10-05T18:50:48.037420Z",
     "iopub.status.idle": "2020-10-05T18:50:50.996356Z",
     "shell.execute_reply": "2020-10-05T18:50:50.995748Z"
    },
    "papermill": {
     "duration": 2.988287,
     "end_time": "2020-10-05T18:50:50.996484",
     "exception": false,
     "start_time": "2020-10-05T18:50:48.008197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T18:50:51.052325Z",
     "iopub.status.busy": "2020-10-05T18:50:51.051703Z",
     "iopub.status.idle": "2020-10-05T18:50:51.055845Z",
     "shell.execute_reply": "2020-10-05T18:50:51.055318Z"
    },
    "papermill": {
     "duration": 0.032989,
     "end_time": "2020-10-05T18:50:51.055975",
     "exception": false,
     "start_time": "2020-10-05T18:50:51.022986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.053915069524414806"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = Path(\"/../rsna_data/\")\n",
    "train_df = pd.read_csv(datapath/'train.csv')\n",
    "train_df.pe_present_on_image.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load All Image Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdatapath = (datapath/'full_raw_512')\n",
    "files = get_image_files(imgdatapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesdict = defaultdict(list)\n",
    "for o in files: filesdict[o.parent.name] += [o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7279"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filesdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = dict(zip(train_df['SOPInstanceUID'], train_df['pe_present_on_image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1790594, 1790594)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files), len(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(o): return labels_dict[o.stem.split(\"_\")[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = datapath/'metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_files = get_files(metadata_path, extensions='.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#7279) [Path('/../rsna_data/metadata/de6cf946cacb.csv'),Path('/../rsna_data/metadata/0d548bca2844.csv'),Path('/../rsna_data/metadata/6d6432ccbeac.csv'),Path('/../rsna_data/metadata/f8b0b66c706f.csv'),Path('/../rsna_data/metadata/064153f367c0.csv'),Path('/../rsna_data/metadata/ea930c47a345.csv'),Path('/../rsna_data/metadata/0f1d90963f0f.csv'),Path('/../rsna_data/metadata/6c217cee8898.csv'),Path('/../rsna_data/metadata/4d7a4494d46d.csv'),Path('/../rsna_data/metadata/1346256ea0e8.csv')...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid2metadata = {o.stem:pd.read_csv(o) for o in metadata_files}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Fold PIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_cv = True\n",
    "FOLD = 4\n",
    "\n",
    "if do_cv: \n",
    "    cv_pids_dir = (datapath/'cv_pids')\n",
    "    if not cv_pids_dir.exists(): cv_pids_dir.mkdir()\n",
    "    cv_df = train_df[['StudyInstanceUID', 'negative_exam_for_pe']].drop_duplicates().reset_index(drop=True)\n",
    "    all_pids = cv_df['StudyInstanceUID'].values\n",
    "    valid_pids = pd.read_pickle(datapath/f'cv_pids/pids_fold{FOLD}.pkl')\n",
    "    train_pids = list(set(all_pids).difference(valid_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5824, 1455, 7279)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pids), len(valid_pids), len(train_pids+valid_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadf = pd.concat([pid2metadata[o] for o in train_pids]).reset_index(drop=True)\n",
    "valid_metadf = pd.concat([pid2metadata[o]  for o in valid_pids]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Valid Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files,valid_files = [],[]\n",
    "for o in train_pids: train_files += filesdict[o]\n",
    "for o in valid_pids: valid_files += filesdict[o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1434610, 355984, 1790594)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_files), len(valid_files), len(train_files+valid_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(f\"./models/xresnet34-{resize}-PR-fold{FOLD}-export.pkl\", cpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get preds & Visual Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingHook:\n",
    "    def __init__(self, m, savedir, filename, csz=5000000):\n",
    "        store_attr(\"m,savedir,filename,csz\")\n",
    "        \n",
    "        if len(m._forward_hooks) > 0: self.reset()\n",
    "        \n",
    "        self.embeddings = tensor([])\n",
    "        self.hook = Hook(m, self.hook_fn, cpu=True)\n",
    "        self.save_iter = 0   \n",
    "        \n",
    "        savedir = Path(savedir)\n",
    "        if not savedir.exists(): savedir.mkdir()\n",
    "    \n",
    "    def hook_fn(self, m, inp, out): \n",
    "        \"Stack and save computed embeddings\"\n",
    "        self.embeddings = torch.cat([self.embeddings, out])\n",
    "        if self.embeddings.shape[0] > self.csz:\n",
    "            self.save()\n",
    "            self.embeddings = tensor([])\n",
    "    \n",
    "    def reset(self): self.m._forward_hooks = OrderedDict()\n",
    "        \n",
    "    def save(self): \n",
    "        torch.save(self.embeddings, savedir/filename+\"_part{self.save_iter}.pth\")\n",
    "        self.save_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = learn.dls.test_dl(valid_files, with_labels=True, bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embhook = EmbeddingHook(learn.model[1][1], datapath/f'cnn_embs/full_{resize}_FOLD{FOLD}', 'xresnet34_embeddings.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds, targs = learn.get_preds(dl=valid_dl, act=noop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([355984, 2]), torch.Size([355984]), torch.Size([355984, 1024]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape, targs.shape, embhook.embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preds, embeddings and ordered valid filenames\n",
    "torch.save(embhook.embeddings,  datapath/f'cnn_embs/full_{resize}_FOLD{FOLD}'/'embeddings.pth')\n",
    "torch.save(preds,  datapath/f'cnn_embs/full_{resize}_FOLD{FOLD}'/'preds.pth')\n",
    "torch.save(valid_dl.dataset.items,  datapath/f'cnn_embs/full_{resize}_FOLD{FOLD}'/'files.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Weighted Log Loss\n",
    "\n",
    "**sz 256**\n",
    "\n",
    "Fold 0, sz=256, temp=1.3, 0.3881\n",
    "\n",
    "Fold 1, sz=256, temp = 1.3, 0.3684\n",
    "\n",
    "**sz 512**\n",
    "\n",
    "Fold 0, sz=512, temp =0.8 0.2639\n",
    "\n",
    "Fold 1, sz=512, temp = 1.5, 0.2679\n",
    "\n",
    "Fold 2  sz=512, temp = 1.4, 0.2686\n",
    "\n",
    "Fold 3 sz=512, temp = 1.1, 0.2373\n",
    "\n",
    "Fold 4 sz=512, temp = 1.1, 0.2533"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qi = proportion of positive images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels = L(valid_files).map(get_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9451379837296058"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_p = np.mean(valid_labels)\n",
    "1-valid_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9395)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sids = L(valid_files).map(lambda o: o.parent.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid2qi =dict(pd.DataFrame({\"sid\":sids, \"labels\": valid_labels}).groupby(\"sid\")['labels'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "qis = tensor([sid2qi[o] for o in sids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 1.4429523944854736\n",
      "0.2 0.7361778020858765\n",
      "0.3 0.5075522661209106\n",
      "0.4 0.39870545268058777\n",
      "0.5 0.33796584606170654\n",
      "0.6 0.30145129561424255\n",
      "0.7 0.27892276644706726\n",
      "0.7999999999999999 0.26523709297180176\n",
      "0.8999999999999999 0.25750088691711426\n",
      "0.9999999999999999 0.25393974781036377\n",
      "1.0999999999999999 0.2533901631832123\n",
      "1.2 0.2550487816333771\n",
      "1.3 0.2583395540714264\n",
      "1.4 0.26283755898475647\n",
      "1.5 0.2682230472564697\n",
      "1.5999999999999999 0.2742520272731781\n",
      "1.7 0.28073635697364807\n",
      "1.8 0.28753021359443665\n",
      "1.9 0.29452037811279297\n",
      "2.0 0.3016183078289032\n"
     ]
    }
   ],
   "source": [
    "for temp in np.linspace(0.1, 2, 20):\n",
    "    l = F.cross_entropy(preds.float()/temp, targs, reduction='none')\n",
    "    avg_logloss = (l*qis).sum()/qis.sum()\n",
    "    print(temp, avg_logloss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18657.0137)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qis.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((preds.float()/.8).softmax(1)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_losses = F.cross_entropy(preds.float()/0.8, targs, reduction='none')\n",
    "tot_img_loss = (img_losses*qis).sum()\n",
    "tot_img_wgts = qis.sum()\n",
    "avg_logloss = tot_img_loss/tot_img_wgts;avg_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_img_loss, tot_img_wgts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exam Weighted Log Loss\n",
    "\n",
    "**Mean baseline**\n",
    "\n",
    "Fold 1 0.3518\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_targets = L([\n",
    "#           'positive_exam_for_pe'\n",
    "            'negative_exam_for_pe',\n",
    "            'indeterminate',\n",
    "\n",
    "            'rv_lv_ratio_gte_1',\n",
    "            'rv_lv_ratio_lt_1',\n",
    "    # none\n",
    "\n",
    "            'leftsided_pe',\n",
    "            'rightsided_pe',\n",
    "            'central_pe',\n",
    "\n",
    "            'chronic_pe',\n",
    "            'acute_and_chronic_pe',           \n",
    "            # neither chronic or acute_and_chronic\n",
    "          \n",
    "    \n",
    "    \n",
    "#             'qa_motion',\n",
    "#             'qa_contrast',\n",
    "#             'flow_artifact',\n",
    "#             'true_filling_defect_not_pe',\n",
    "             ]); exam_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pe_wgt = 0.0736196319\n",
    "indeterminate_wgt = 0.09202453988\n",
    "\n",
    "rv_lv_gte_1_wgt = 0.2346625767\n",
    "rv_lv_lt_1_wgt = 0.0782208589\n",
    "\n",
    "left_pe_wgt = 0.06257668712\n",
    "right_pe_wgt = 0.06257668712\n",
    "central_pe_wgt = 0.1877300613\n",
    "\n",
    "chronic_wgt = 0.1042944785\n",
    "acute_chronic_wgt = 0.1042944785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_wgts = tensor([0.0736196319,0.09202453988,0.2346625767,0.0782208589,0.06257668712,0.06257668712,0.1877300613,0.1042944785, 0.1042944785])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targsdf = train_df[train_df.StudyInstanceUID.isin(train_pids)][[\"StudyInstanceUID\"]+exam_targets].drop_duplicates()\n",
    "valid_targsdf = train_df[train_df.StudyInstanceUID.isin(valid_pids)][[\"StudyInstanceUID\"]+exam_targets].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_mean_preds = dict(train_targsdf[exam_targets].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_mean_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_losses = F.binary_cross_entropy(tensor(list(exam_mean_preds.values()))[None,...].repeat(len(valid_pids),1),\n",
    "                                     tensor(valid_targsdf[exam_targets].values).float(), \n",
    "                                     reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_exam_loss = (exam_losses*exam_wgts).sum()\n",
    "tot_exam_wgts = (len(valid_pids)*exam_wgts.sum())\n",
    "avg_exam_loss = tot_exam_loss/tot_exam_wgts; avg_exam_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine both\n",
    "\n",
    "Almost equal weights just take mean of two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_wgt = 0.07361963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tot_img_loss*img_wgt + tot_exam_loss) / (tot_img_wgts*img_wgt + tot_exam_wgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
