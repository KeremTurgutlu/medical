{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-11T05:05:45.793338Z",
     "iopub.status.busy": "2020-10-11T05:05:45.792450Z",
     "iopub.status.idle": "2020-10-11T05:05:49.076759Z",
     "shell.execute_reply": "2020-10-11T05:05:49.075652Z"
    },
    "papermill": {
     "duration": 3.336839,
     "end_time": "2020-10-11T05:05:49.076897",
     "exception": false,
     "start_time": "2020-10-11T05:05:45.740058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:05:49.185018Z",
     "iopub.status.busy": "2020-10-11T05:05:49.184171Z",
     "iopub.status.idle": "2020-10-11T05:05:49.189192Z",
     "shell.execute_reply": "2020-10-11T05:05:49.188571Z"
    },
    "papermill": {
     "duration": 0.060899,
     "end_time": "2020-10-11T05:05:49.189320",
     "exception": false,
     "start_time": "2020-10-11T05:05:49.128421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:05:49.300079Z",
     "iopub.status.busy": "2020-10-11T05:05:49.297793Z",
     "iopub.status.idle": "2020-10-11T05:05:49.301115Z",
     "shell.execute_reply": "2020-10-11T05:05:49.301698Z"
    },
    "papermill": {
     "duration": 0.062115,
     "end_time": "2020-10-11T05:05:49.301967",
     "exception": false,
     "start_time": "2020-10-11T05:05:49.239852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datapath = Path(\"/home/code-base/scratch_space/rsna_data/\")\n",
    "embspath = Path(datapath/\"cnn_embs\")\n",
    "train_df = pd.read_csv(datapath/'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:05:49.406694Z",
     "iopub.status.busy": "2020-10-11T05:05:49.405658Z",
     "iopub.status.idle": "2020-10-11T05:05:49.414597Z",
     "shell.execute_reply": "2020-10-11T05:05:49.415154Z"
    },
    "papermill": {
     "duration": 0.062231,
     "end_time": "2020-10-11T05:05:49.415312",
     "exception": false,
     "start_time": "2020-10-11T05:05:49.353081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_512_ALL_FROM_FOLD2'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_effb3_256_FOLD0'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_effb3_512_FOLD0'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_512_ALL_FROM_FOLD1'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_512_ALL_FROM_FOLD0'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_512_FOLD1'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_512_FOLD2'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_512_FOLD3'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_512_ALL_FROM_FOLD3'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/.ipynb_checkpoints'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_EFFNETB3_512_ALL_FROM_FOLD0'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_512_FOLD0'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_512_FOLD4'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_512_ALL_FROM_FOLD4')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(embspath.ls())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embeddings & Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_512_ALL_FROM_FOLD0/xresnet34_embeddings_part0.pth'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_512_ALL_FROM_FOLD0/files.pth'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_512_ALL_FROM_FOLD0/xresnet34_embeddings_finalpart.pth'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_512_ALL_FROM_FOLD0/preds.pth'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_512_ALL_FROM_FOLD0/xresnet34_embeddings_part2.pth'),\n",
       " Path('/home/code-base/scratch_space/rsna_data/cnn_embs/full_512_ALL_FROM_FOLD0/xresnet34_embeddings_part1.pth')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold = 0\n",
    "folddir = embspath/f'full_512_ALL_FROM_FOLD{fold}'; list(folddir.ls())\n",
    "# folddir = embspath/f'full_EFFNETB3_512_ALL_FROM_FOLD{fold}'; list(folddir.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.cat([torch.load(folddir/f\"xresnet34_embeddings_{o}.pth\") for o in [\"part0\", \"part1\", \"part2\", \"finalpart\"]])\n",
    "# embeddings = torch.cat([torch.load(folddir/f\"effb3_embeddings_{o}.pth\") for o in [\"part0\", \"part1\", \"part2\", \"finalpart\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.load(folddir/\"preds.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = torch.load(folddir/\"files.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1790594, 1024]), torch.Size([1790594, 2]), 1790594)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape, preds.shape, len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:06:02.291654Z",
     "iopub.status.busy": "2020-10-11T05:06:02.290630Z",
     "iopub.status.idle": "2020-10-11T05:06:04.669685Z",
     "shell.execute_reply": "2020-10-11T05:06:04.668876Z"
    },
    "papermill": {
     "duration": 2.459056,
     "end_time": "2020-10-11T05:06:04.669846",
     "exception": false,
     "start_time": "2020-10-11T05:06:02.210790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add zero for padded input idx\n",
    "input_pad_idx = len(embeddings)\n",
    "embeddings = torch.cat([embeddings, torch.zeros_like(embeddings[:1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for effnet\n",
    "embeddings = embeddings.squeeze(-1).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:06:04.777990Z",
     "iopub.status.busy": "2020-10-11T05:06:04.777188Z",
     "iopub.status.idle": "2020-10-11T05:06:04.808896Z",
     "shell.execute_reply": "2020-10-11T05:06:04.809521Z"
    },
    "papermill": {
     "duration": 0.089675,
     "end_time": "2020-10-11T05:06:04.809681",
     "exception": false,
     "start_time": "2020-10-11T05:06:04.720006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0.,  ..., 0., 0., 0.]), torch.Size([1790595, 1024]), 1790594)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[input_pad_idx], embeddings.shape, input_pad_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3467, -1.3633, -0.9565,  ..., -1.1660,  0.1888, -1.2041],\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.059194,
     "end_time": "2020-10-11T05:06:06.026914",
     "exception": false,
     "start_time": "2020-10-11T05:06:05.967720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Metadata Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = datapath/'metadata'\n",
    "metadata_files = get_files(metadata_path, extensions=\".csv\")\n",
    "metadf = pd.concat([pd.read_csv(o) for o in metadata_files]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1790594, 68)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7279"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metadf['StudyInstanceUID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:06:17.292586Z",
     "iopub.status.busy": "2020-10-11T05:06:17.291549Z",
     "iopub.status.idle": "2020-10-11T05:06:17.294816Z",
     "shell.execute_reply": "2020-10-11T05:06:17.294243Z"
    },
    "papermill": {
     "duration": 0.064378,
     "end_time": "2020-10-11T05:06:17.294933",
     "exception": false,
     "start_time": "2020-10-11T05:06:17.230555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def minmax_scaler(o): return (o - min(o))/(max(o) - min(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:06:17.445353Z",
     "iopub.status.busy": "2020-10-11T05:06:17.444256Z",
     "iopub.status.idle": "2020-10-11T05:06:22.860066Z",
     "shell.execute_reply": "2020-10-11T05:06:22.860899Z"
    },
    "papermill": {
     "duration": 5.51184,
     "end_time": "2020-10-11T05:06:22.861149",
     "exception": false,
     "start_time": "2020-10-11T05:06:17.349309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaled_pos = metadf.groupby('StudyInstanceUID')['ImagePositionPatient2'].apply(minmax_scaler)\n",
    "metadf.loc[:,'scaled_position'] = scaled_pos.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_feat_cols = ['scaled_position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isnan(metadf[meta_feat_cols]).sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std = metadf[meta_feat_cols].agg(['mean', 'std']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaled_position': [0.5078721739409284, 0.29139548181397823]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std_dict = dict(zip(mean_std.index, mean_std.values.tolist())); mean_std_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scaler for training\n",
    "for c in mean_std_dict: metadf[c] = (metadf[c] - mean_std_dict[c][0]) / mean_std_dict[c][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:06:25.160602Z",
     "iopub.status.busy": "2020-10-11T05:06:25.159131Z",
     "iopub.status.idle": "2020-10-11T05:06:26.563722Z",
     "shell.execute_reply": "2020-10-11T05:06:26.564383Z"
    },
    "papermill": {
     "duration": 1.47135,
     "end_time": "2020-10-11T05:06:26.564553",
     "exception": false,
     "start_time": "2020-10-11T05:06:25.093203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_feats_dict = dict(zip(metadf['SOPInstanceUID'], metadf[meta_feat_cols].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1790594"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meta_feats_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fold Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_embeddings = []\n",
    "for o in files:\n",
    "    sopid = o.stem.split(\"_\")[1]\n",
    "    meta_embeddings.append(meta_feats_dict[sopid])\n",
    "meta_embeddings = np.vstack(meta_embeddings)\n",
    "meta_embeddings= tensor(meta_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_preds = True\n",
    "if use_preds:\n",
    "    meta_embeddings = torch.cat([meta_embeddings, preds[:,1].view(-1,1).float()],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1790594, 2]), torch.Tensor)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_embeddings.shape, type(meta_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:06:32.294054Z",
     "iopub.status.busy": "2020-10-11T05:06:32.292530Z",
     "iopub.status.idle": "2020-10-11T05:06:32.320193Z",
     "shell.execute_reply": "2020-10-11T05:06:32.319610Z"
    },
    "papermill": {
     "duration": 0.095233,
     "end_time": "2020-10-11T05:06:32.320333",
     "exception": false,
     "start_time": "2020-10-11T05:06:32.225100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_embeddings = torch.cat([meta_embeddings, torch.zeros_like(meta_embeddings[:1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:06:32.448767Z",
     "iopub.status.busy": "2020-10-11T05:06:32.447837Z",
     "iopub.status.idle": "2020-10-11T05:06:32.451520Z",
     "shell.execute_reply": "2020-10-11T05:06:32.452084Z"
    },
    "papermill": {
     "duration": 0.070835,
     "end_time": "2020-10-11T05:06:32.452228",
     "exception": false,
     "start_time": "2020-10-11T05:06:32.381393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1790595, 1024]), torch.Size([1790595, 2]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape, meta_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_embeddings = torch.cat([embeddings, meta_embeddings], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1790595, 1026])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.5664, 12.0469,  1.0723,  ...,  0.3210,  1.3457, -1.3467],\n",
       "        [ 4.5781,  1.9736,  5.1953,  ...,  1.1133, -0.7914, -1.3633],\n",
       "        [ 9.6797,  2.4531,  7.2617,  ...,  0.9951, -0.9785, -0.9565],\n",
       "        ...,\n",
       "        [12.5312,  1.9893, 10.1328,  ...,  1.5674, -0.7226,  0.1888],\n",
       "        [ 8.1797,  2.8672, 18.1094,  ...,  1.2500, -1.0009, -1.2041],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.061828,
     "end_time": "2020-10-11T05:06:32.576011",
     "exception": false,
     "start_time": "2020-10-11T05:06:32.514183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:14:57.762494Z",
     "iopub.status.busy": "2020-10-11T05:14:57.761573Z",
     "iopub.status.idle": "2020-10-11T05:14:57.765257Z",
     "shell.execute_reply": "2020-10-11T05:14:57.765857Z"
    },
    "papermill": {
     "duration": 0.075197,
     "end_time": "2020-10-11T05:14:57.766007",
     "exception": false,
     "start_time": "2020-10-11T05:14:57.690810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_targets = ['pe_present_on_image']\n",
    "exam_targets = [\n",
    "    'negative_exam_for_pe', # exam level\n",
    "    'rv_lv_ratio_gte_1', # exam level\n",
    "    'rv_lv_ratio_lt_1', # exam level\n",
    "    'leftsided_pe', # exam level\n",
    "    'chronic_pe', # exam level\n",
    "    'rightsided_pe', # exam level\n",
    "    'acute_and_chronic_pe', # exam level\n",
    "    'central_pe', # exam level\n",
    "    'indeterminate' # exam level\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df = train_df[['StudyInstanceUID', 'SeriesInstanceUID', 'SOPInstanceUID']+image_targets+exam_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_dict = dict(zip(targets_df['SOPInstanceUID'].values, targets_df[image_targets+exam_targets].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1790594"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(targets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dict = defaultdict(list)\n",
    "for i,o in enumerate(files):\n",
    "    slice_no, sopid = o.stem.split(\"_\")\n",
    "    sid = o.parent.name\n",
    "    slice_no = int(slice_no)        \n",
    "    files_dict[sid].append({\"slice_no\":slice_no, \"embs_idx\":i, \"img_y\":targets_dict[sopid][0], \"exam_y\":targets_dict[sopid][1:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pids = list(files_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7279"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:14:58.242901Z",
     "iopub.status.busy": "2020-10-11T05:14:58.241793Z",
     "iopub.status.idle": "2020-10-11T05:14:58.244246Z",
     "shell.execute_reply": "2020-10-11T05:14:58.244925Z"
    },
    "papermill": {
     "duration": 0.087384,
     "end_time": "2020-10-11T05:14:58.245064",
     "exception": false,
     "start_time": "2020-10-11T05:14:58.157680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_x(pid, files_dict):\n",
    "    o = files_dict[pid]    \n",
    "    l = sorted(o, key=lambda x: x['slice_no']) \n",
    "    return tensor([o['embs_idx'] for o in l])\n",
    "\n",
    "def get_img_y(pid, files_dict):\n",
    "    o = files_dict[pid]    \n",
    "    l = sorted(o, key=lambda x: x['slice_no']) \n",
    "    img_y = [o['img_y'] for o in l]\n",
    "    img_y = tensor(img_y).float()\n",
    "    return img_y\n",
    "\n",
    "def get_exam_y(pid, files_dict):\n",
    "    d = files_dict[pid][0]        \n",
    "    exam_y = tensor(d['exam_y']).float()\n",
    "    return exam_y\n",
    "    \n",
    "# before_batch: after collecting samples before collating\n",
    "targ_pad_idx = 666\n",
    "def SequenceBlock():       return  TransformBlock(type_tfms=[partial(get_x, files_dict=files_dict)], \n",
    "                                                  dl_type=SortedDL,\n",
    "                                                  dls_kwargs={'before_batch':\n",
    "                                                               [partial(pad_input, pad_idx=input_pad_idx),\n",
    "                                                                partial(pad_input, pad_idx=targ_pad_idx, pad_fields=1)]})\n",
    "def SequenceTargetBlock(): return TransformBlock(type_tfms=[partial(get_img_y, files_dict=files_dict)])\n",
    "def TargetBlock():         return TransformBlock(type_tfms=[partial(get_exam_y, files_dict=files_dict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_img_y(all_pids[0], files_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_exam_y(all_pids[0], files_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_embeddings = F.normalize(combined_embeddings, dim=0)\n",
    "# normalized_embeddings.isnan().sum()\n",
    "# normalized_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert combined_embeddings.isnan().sum().item() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.067288,
     "end_time": "2020-10-11T05:15:15.313125",
     "exception": false,
     "start_time": "2020-10-11T05:15:15.245837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:15:15.454478Z",
     "iopub.status.busy": "2020-10-11T05:15:15.453583Z",
     "iopub.status.idle": "2020-10-11T05:15:15.457163Z",
     "shell.execute_reply": "2020-10-11T05:15:15.457702Z"
    },
    "papermill": {
     "duration": 0.076828,
     "end_time": "2020-10-11T05:15:15.457883",
     "exception": false,
     "start_time": "2020-10-11T05:15:15.381055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = default_device(); device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWD_LSTM(Module):\n",
    "    \"AWD-LSTM inspired by https://arxiv.org/abs/1708.02182\"\n",
    "    initrange=0.1\n",
    "\n",
    "    def __init__(self, emb_sz,n_hid, n_layers, hidden_p=0.2, input_p=0.6, weight_p=0.5, bidir=False):\n",
    "        store_attr('emb_sz,n_hid,n_layers')\n",
    "        self.bs = 1\n",
    "        self.n_dir = 2 if bidir else 1\n",
    "        \n",
    "        self.rnns = nn.ModuleList([self._one_rnn(emb_sz if l == 0 else n_hid, (n_hid)//self.n_dir, bidir, weight_p, l) for l in range(n_layers)])\n",
    "\n",
    "        self.input_dp = RNNDropout(input_p)\n",
    "        self.hidden_dps = nn.ModuleList([RNNDropout(hidden_p) for l in range(n_layers)])\n",
    "        self.reset()\n",
    "\n",
    "    def forward(self, x, from_embeds=False):\n",
    "        \n",
    "        if from_embeds: inp = x\n",
    "        else: inp = combined_embeddings[x].to(device)\n",
    "        bs,sl = inp.shape[:2]\n",
    "        if bs!=self.bs: self._change_hidden(bs)\n",
    "\n",
    "        output = self.input_dp(inp)\n",
    "        new_hidden = []\n",
    "        for l, (rnn,hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):\n",
    "            output, new_h = rnn(output, self.hidden[l])\n",
    "            new_hidden.append(new_h)\n",
    "            if l != self.n_layers - 1: output = hid_dp(output)\n",
    "        self.hidden = to_detach(new_hidden, cpu=False, gather=False)\n",
    "        return output\n",
    "\n",
    "    def _change_hidden(self, bs):\n",
    "        self.hidden = [self._change_one_hidden(l, bs) for l in range(self.n_layers)]\n",
    "        self.bs = bs\n",
    "\n",
    "    def _one_rnn(self, n_in, n_out, bidir, weight_p, l):\n",
    "        \"Return one of the inner rnn\"\n",
    "        rnn = nn.LSTM(n_in, n_out, 1, batch_first=True, bidirectional=bidir, bias=False)\n",
    "        return WeightDropout(rnn, weight_p)\n",
    "\n",
    "    def _one_hidden(self, l):\n",
    "        \"Return one hidden state\"\n",
    "        nh = (self.n_hid) // self.n_dir\n",
    "        return (one_param(self).new_zeros(self.n_dir, self.bs, nh), one_param(self).new_zeros(self.n_dir, self.bs, nh))\n",
    "\n",
    "    def _change_one_hidden(self, l, bs):\n",
    "        if self.bs < bs:\n",
    "            nh = (self.n_hid) // self.n_dir\n",
    "            return tuple(torch.cat([h, h.new_zeros(self.n_dir, bs-self.bs, nh)], dim=1) for h in self.hidden[l])\n",
    "        if self.bs > bs: return (self.hidden[l][0][:,:bs].contiguous(), self.hidden[l][1][:,:bs].contiguous())\n",
    "        return self.hidden[l]\n",
    "\n",
    "    def reset(self):\n",
    "        \"Reset the hidden states\"\n",
    "        [r.reset() for r in self.rnns if hasattr(r, 'reset')]\n",
    "        self.hidden = [self._one_hidden(l) for l in range(self.n_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_width = 512\n",
    "layers = [lstm_width * 3] + [lstm_width] + [9]\n",
    "\n",
    "class MultiHeadedSequenceClassifier(Module):\n",
    "    \"dim: input sequence feature dim\"\n",
    "    def __init__(self, bptt=72, input_pad_idx=input_pad_idx, n_meta=1, dim=1024, nlayers=2, cls_ps=[0.4, 0.1], **awd_kwargs):\n",
    "        \n",
    "        store_attr('input_pad_idx')\n",
    "        self.awd_lstm = AWD_LSTM(dim+n_meta, lstm_width, nlayers, bidir=True, **awd_kwargs)\n",
    "#         self.awd_lstm = AWD_QRNN(dim+n_meta, 512, 2, bidir=True)\n",
    "        self.encoder = SentenceEncoder(bptt=bptt, module=self.awd_lstm, pad_idx=input_pad_idx)\n",
    "        \n",
    "        # image level preds\n",
    "        self.seq_head = LinearDecoder(1, lstm_width, bias=True)\n",
    " \n",
    "        # exam level preds\n",
    "        self.exam_head = PoolingLinearClassifier(layers, ps=cls_ps, bptt=bptt)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, mask = self.encoder(x) \n",
    "       \n",
    "        # img level out\n",
    "        seq_cls_out,_,_ = self.seq_head(out)\n",
    "        seq_cls_out = seq_cls_out.squeeze(-1)\n",
    "              \n",
    "        # exam level out\n",
    "        exam_out,_,_ = self.exam_head((out,mask))\n",
    "\n",
    "        return (seq_cls_out, exam_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:15:16.063649Z",
     "iopub.status.busy": "2020-10-11T05:15:16.061541Z",
     "iopub.status.idle": "2020-10-11T05:15:16.064593Z",
     "shell.execute_reply": "2020-10-11T05:15:16.065170Z"
    },
    "papermill": {
     "duration": 0.085322,
     "end_time": "2020-10-11T05:15:16.065356",
     "exception": false,
     "start_time": "2020-10-11T05:15:15.980034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiLoss(Module):\n",
    "    \n",
    "    def __init__(self, targ_pad_idx=666):\n",
    "        store_attr(\"targ_pad_idx\")\n",
    "\n",
    "    def forward(self, inp, yb0, yb1):\n",
    "        image_target_weight = 0.07361963\n",
    "        exam_target_weights = tensor([0.0736196319, 0.2346625767,  0.0782208589, \n",
    "                                      0.06257668712, 0.1042944785, 0.06257668712,\n",
    "                                      0.1042944785,  0.1877300613, 0.09202453988]).to(yb1.device)\n",
    "        seq_cls_out, exam_out = inp\n",
    "       \n",
    "        # img loss\n",
    "        mask = yb0 != self.targ_pad_idx \n",
    "        \n",
    "        img_loss, qs = 0, 0        \n",
    "        for _m,_y,_p in zip(mask, yb0, seq_cls_out):\n",
    "            qi = _y[_m].mean()\n",
    "            qs += image_target_weight*qi*sum(_m)\n",
    "            img_loss += image_target_weight*qi*(F.binary_cross_entropy_with_logits(_p[_m], _y[_m], reduction='sum'))\n",
    "        \n",
    "        # exam loss\n",
    "        exam_losses = F.binary_cross_entropy_with_logits(exam_out, yb1,reduction='none')\n",
    "        tot_exam_loss = (exam_losses*(exam_target_weights.unsqueeze(0))).sum()\n",
    "        tot_exam_wgts = len(exam_losses)*(tensor(exam_target_weights).sum())\n",
    "        \n",
    "        return (tot_exam_loss+img_loss)/(qs+tot_exam_wgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLoss(Module):\n",
    "    \n",
    "    def __init__(self, targ_pad_idx=666):\n",
    "        store_attr(\"targ_pad_idx\")\n",
    "\n",
    "    def forward(self, inp, yb0, yb1):\n",
    "#         exam_targets = [\n",
    "#     'negative_exam_for_pe', # exam level\n",
    "#     'rv_lv_ratio_gte_1', # exam level\n",
    "#     'rv_lv_ratio_lt_1', # exam level\n",
    "#     'leftsided_pe', # exam level\n",
    "#     'chronic_pe', # exam level\n",
    "#     'rightsided_pe', # exam level\n",
    "#     'acute_and_chronic_pe', # exam level\n",
    "#     'central_pe', # exam level\n",
    "#     'indeterminate' # exam level\n",
    "# ]\n",
    "        image_target_weight = 0.07361963\n",
    "        exam_target_weights = tensor([0.0736196319, 0.2346625767,  0.0782208589, \n",
    "                                      0.06257668712, 0.1042944785, 0.06257668712,\n",
    "                                      0.1042944785,  0.1877300613, 0.09202453988]).to(yb1.device)\n",
    "        seq_cls_out, exam_out = inp\n",
    "       \n",
    "        # img loss\n",
    "        mask = yb0 != self.targ_pad_idx \n",
    "        \n",
    "        img_loss, qs = 0, 0        \n",
    "        for _m,_y,_p in zip(mask, yb0, seq_cls_out):\n",
    "            qi = _y[_m].mean()\n",
    "            qs += image_target_weight*qi*sum(_m)\n",
    "            img_loss += image_target_weight*qi*(F.binary_cross_entropy_with_logits(_p[_m], _y[_m], reduction='sum'))\n",
    "        \n",
    "        return (img_loss)/(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExamLoss(Module):\n",
    "    \n",
    "    def __init__(self, targ_pad_idx=666):\n",
    "        store_attr(\"targ_pad_idx\")\n",
    "\n",
    "    def forward(self, inp, yb0, yb1):\n",
    "        exam_target_weights = tensor([0.0736196319, 0.2346625767,  0.0782208589, \n",
    "                                      0.06257668712, 0.1042944785, 0.06257668712,\n",
    "                                      0.1042944785,  0.1877300613, 0.09202453988]).to(yb1.device)\n",
    "        seq_cls_out, exam_out = inp\n",
    "       \n",
    "        # exam loss\n",
    "        exam_losses = F.binary_cross_entropy_with_logits(exam_out, yb1,reduction='none')\n",
    "        tot_exam_loss = (exam_losses*(exam_target_weights.unsqueeze(0))).sum()\n",
    "        tot_exam_wgts = len(exam_losses)*(tensor(exam_target_weights).sum())\n",
    "        \n",
    "        return (tot_exam_loss)/(tot_exam_wgts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.06882,
     "end_time": "2020-10-11T05:15:17.244609",
     "exception": false,
     "start_time": "2020-10-11T05:15:17.175789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_cv = True\n",
    "FOLD = fold\n",
    "\n",
    "if do_cv: \n",
    "    valid_pids = pd.read_pickle(datapath/f'cv_pids/pids_fold{FOLD}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1456"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1790595, 1026])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:15:17.426109Z",
     "iopub.status.busy": "2020-10-11T05:15:17.415917Z",
     "iopub.status.idle": "2020-10-11T05:15:27.320616Z",
     "shell.execute_reply": "2020-10-11T05:15:27.319925Z"
    },
    "papermill": {
     "duration": 10.007464,
     "end_time": "2020-10-11T05:15:27.320767",
     "exception": false,
     "start_time": "2020-10-11T05:15:17.313303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = DataBlock(blocks=(SequenceBlock,SequenceTargetBlock,TargetBlock), \n",
    "                 n_inp=1, \n",
    "                 splitter=FuncSplitter(lambda o: True if o in valid_pids else False)\n",
    "                )\n",
    "dls = data.dataloaders(all_pids, bs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:15:17.426109Z",
     "iopub.status.busy": "2020-10-11T05:15:17.415917Z",
     "iopub.status.idle": "2020-10-11T05:15:27.320616Z",
     "shell.execute_reply": "2020-10-11T05:15:27.319925Z"
    },
    "papermill": {
     "duration": 10.007464,
     "end_time": "2020-10-11T05:15:27.320767",
     "exception": false,
     "start_time": "2020-10-11T05:15:17.313303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mult = 1.\n",
    "cls_ps = [0.4*mult,0.1*mult]\n",
    "model = SequentialRNN(MultiHeadedSequenceClassifier(bptt=256, n_meta=2, dim=1024, nlayers=2, cls_ps=cls_ps,\n",
    "                                                    hidden_p=0.2*mult, input_p=0.6*mult, weight_p=0.5*mult)) # dim = 1536 for effnet 1024 for xresnet\n",
    "loss_func = MultiLoss()\n",
    "learner = Learner(dls, model, loss_func=loss_func, metrics=[ImageLoss(), ExamLoss()],\n",
    "                  cbs=[ModelResetter(), TerminateOnNaNCallback(),\n",
    "                       SaveModelCallback(fname=f\"nometa_sequence_with_preds_fulldata_fold{fold}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T05:15:52.842784Z",
     "iopub.status.busy": "2020-10-11T05:15:52.841799Z",
     "iopub.status.idle": "2020-10-11T05:24:44.960455Z",
     "shell.execute_reply": "2020-10-11T05:24:44.959303Z"
    },
    "papermill": {
     "duration": 532.207482,
     "end_time": "2020-10-11T05:24:44.960619",
     "exception": false,
     "start_time": "2020-10-11T05:15:52.753137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner.fit_flat_cos(20, lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get OOF Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pid(pid):\n",
    "    return pid\n",
    "\n",
    "def get_x(pid, files_dict):\n",
    "    o = files_dict[pid]    \n",
    "    l = sorted(o, key=lambda x: x['slice_no']) \n",
    "    return tensor([o['embs_idx'] for o in l])\n",
    "\n",
    "def get_img_y(pid, files_dict):\n",
    "    o = files_dict[pid]    \n",
    "    l = sorted(o, key=lambda x: x['slice_no']) \n",
    "    img_y = [o['img_y'] for o in l]\n",
    "    img_y = tensor(img_y).float()\n",
    "    return img_y\n",
    "\n",
    "def get_exam_y(pid, files_dict):\n",
    "    d = files_dict[pid][0]        \n",
    "    exam_y = tensor(d['exam_y']).float()\n",
    "    return exam_y\n",
    "    \n",
    "# before_batch: after collecting samples before collating\n",
    "targ_pad_idx = 666\n",
    "def SequenceBlock():       return  TransformBlock(type_tfms=[partial(get_x, files_dict=files_dict)], \n",
    "                                                  dl_type=SortedDL,\n",
    "                                                  dls_kwargs={'before_batch':\n",
    "                                                               [partial(pad_input, pad_idx=input_pad_idx),\n",
    "                                                                partial(pad_input, pad_idx=targ_pad_idx, pad_fields=1)]})\n",
    "def PidBlock(): return TransformBlock(type_tfms=[get_pid])\n",
    "def SequenceTargetBlock(): return TransformBlock(type_tfms=[partial(get_img_y, files_dict=files_dict)])\n",
    "def TargetBlock():         return TransformBlock(type_tfms=[partial(get_exam_y, files_dict=files_dict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBlock(blocks=(SequenceBlock,SequenceTargetBlock,TargetBlock, PidBlock), \n",
    "                 n_inp=1, \n",
    "                 splitter=FuncSplitter(lambda o: True if o in valid_pids else False)\n",
    "#                 splitter=RandomSplitter(0.3),\n",
    "                )\n",
    "dls = data.dataloaders(all_pids, bs=128)\n",
    "model = SequentialRNN(MultiHeadedSequenceClassifier(bptt=256, n_meta=2, dim=1024, nlayers=2)) # dim = 1536 for effnet 1024 for xresnet\n",
    "loss_func = MultiLoss()\n",
    "learner = Learner(dls, model, loss_func=loss_func, metrics=[],cbs=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load(f\"nometa_sequence_with_preds_fulldata_fold{fold}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.model.eval().to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = learner.dls.test_dl(all_pids, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_pids = []\n",
    "seq_img_preds = []\n",
    "seq_img_targs = []\n",
    "seq_exam_preds = []\n",
    "seq_exam_targs = []\n",
    "with torch.no_grad():\n",
    "    for xb,yb0,yb1,pids in progress_bar(test_dl):\n",
    "        img_pred, exam_pred = to_detach(learner.model(xb))\n",
    "        seq_img_preds.append(img_pred)\n",
    "        seq_img_targs.append(yb0)\n",
    "        seq_exam_preds.append(exam_pred)\n",
    "        seq_exam_targs.append(yb1)\n",
    "        seq_pids.append(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_datapath = datapath/'final_lstm_stacking'\n",
    "if not stacking_datapath.exists(): stacking_datapath.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder = f\"xresnet_FOLD{FOLD}\"\n",
    "stacking_folder = stacking_datapath/subfolder\n",
    "if not stacking_folder.exists(): stacking_folder.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seq_pids), len(seq_img_preds), len(seq_img_targs), len(seq_exam_preds), len(seq_exam_targs), len(valid_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(seq_pids, stacking_folder/'seq_pids.pth')\n",
    "torch.save(seq_img_preds, stacking_folder/'seq_img_preds.pth')\n",
    "torch.save(seq_img_targs, stacking_folder/'seq_img_targs.pth')\n",
    "torch.save(seq_exam_preds, stacking_folder/'seq_exam_preds.pth')\n",
    "torch.save(seq_exam_targs, stacking_folder/'seq_exam_targs.pth')\n",
    "torch.save(valid_pids, stacking_folder/'valid_pids.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.077751,
     "end_time": "2020-10-11T05:24:45.672722",
     "exception": false,
     "start_time": "2020-10-11T05:24:45.594971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1146.351524,
   "end_time": "2020-10-11T05:24:47.674073",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-11T05:05:41.322549",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
